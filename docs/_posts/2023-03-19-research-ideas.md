---
layout: post
title: Research Project Idea
---

Seeing all the news lately regarding the advancements made with GPT-4 really got me excited and thinking back to my senior innovation project in college. I actually got so excited I wrote down my thoughts on a potential research project. I warn you though, this is probably going to be a bit long, so stay with me.

## Abstract
The use of large language models in machine learning has lead to an explosion of tools attempting to improve the productiveness and potency of cybersecurity operations. Many of these efforts appear to be limited in scope and reliant on proprietary methods and data based on the organization's previous industry experience. This project aims to alleviate that misunderstanding and tightly focus on a broader set of training data specifically chosen to provide the model with a data set focused on a more expansive background than the current offerings in development. If successful, this project will provide security analysts with reliable, accurate feedback regarding any cybersecurity activity analysis executed by the project.*

## History
In 2007, as part of my university graduation provisions, which I've [spoken about]({% post_url 2012-02-06-college-projects %}) before, I was required to choose a topic for my capstone. Being a network security student interested in how malicious software worked and having an interest in protecting things as part of my electronic countermeasures field in the military, I chose the topic of proactive computer and network defense. In working through this project from 2007 to 2012; fleshing it out and attempting to build a prototype, I created Project Corezashi. The idea behind Corezashi was very similar to _this_ project in that I proposed using CAPEC data, AV definitions, malware source code, and SANS report data. The difference*, at this point, is that Corezashi was intended to have what I called an countermeasures signature engine that would generate countermeasures based on that data and pass them along to another feature I dubbed the threat analysis engine to verify their effectiveness.

## Proposal
GPT (Generative Pre-trained Transformer) in its various forms from OpenAI, is what's called a large language model in the form of a chat bot designed to respond to questions in natural human language with answers in natural human language. As such and according to information that can be found regarding the project, it is a neural network model using supervised and reinforcement learning techniques trained on five distinct data sets. These data sets include the Common Crawl, WebText2, Books1, Books2, and Wikipedia. While these data sets are certainly comprehensive for the most part, I have been unable to verify that they contain the full context of things like MITRE CAPEC and ATT&CK. With the recent release of the GPT-4 model for public interaction and the open sourcing and release of the GPT-3/3.5 code, it may be time to re-evaluate the feasibility of a project similar to Corezashi.

What I am proposing is actually a two-fold project. First, train a GPT style model on the following specific data sets in addition to the five sets mentioned previously.

- [MITRE CAPEC](https://capec.mitre.org)
- [MITRE ATT&CK](https://attack.mitre.org)
- [MITRE MAEC](https://maecproject.github.io)
- Threat intelligence reporting (Potentially a project of its own to prepare it as training data)
- [Zeek](https://zeek.org)/[Corelight](https://www.corelight.com) logs
- Source code

CAPEC (Common Attack Pattern Enumerations and Classifications) "is a comprehensive dictionary and classification taxonomy of known attacks typically used to advance the community's understanding and enhance defenses" according to MITRE's website. The data from CAPEC is based on CVE (Common Vulnerabilities and Exposures) and CWE (Common Weakness Enumeration) datasets. The good news here is that the CAPEC data appears to be available in a format conducive to the required pre-processing for traditional machine learning. This means that there is potentially less work required in order to use it as training data.

ATT&CK (Adversarial Tactics, Techniques and Common Knowledge) is focused on the network defense and describing the operational phases in an adversary's life cycle with tactics, techniques, and procedures according to MITRE's website. Also according to MITRE, many of hte attack patterns enumerated by CAPEC are used by adversaries via specific techniques described by ATT&CK which are cross referenced "where appropriate". This data also appears to be available in a format conducive to pre-processing efforts, making it less of a struggle to use, hopefully.

The MAEC project seems to enjoy less direct attention from MITRE, since it doesn't have a page on their own site. However, the Malware Attribute Enumeration and Characterization project is intended to be a community-developed structured language for encoding and sharing high-fidelity information about malware based on attributes such as behaviors, artifacts, and relationships between samples according to it's website. This project has also apparently been incorporated by a few organizations that you may all have heard of, Joe Sandbox, Palo Alto, Cuckoo, Reversing Labs, and Bromium. Many of the web pages for this project appear to be broken and work appears to have paused or stopped in October of 2022.

The collection, correlation, and processing of threat intelligence information regarding malware and adversaries is where MAEC and ATT&CK seem to be stemming from. While it may be easier to use those projects exclusively, due to the lack of recent work on MAEC and the apparent lack of correlation between MAEC/ATT&CK/CAPEC, it may be better to just pull in all of the professional threat intelligence feeds feasible and compile this dataset ourselves. Performing these actions is no trivial matter could be a project in-and-of-itself. This is not a journey to embark upon lightly. It would require the parsing and formatting of all reporting into a standardized dataset including all artifacts/IOCs as well as adversarial identification and correlation where possible.

Working with Zeek or Corelight logs would potentially be less complicated than other datasets due to the fact that they are stored in a standardized manner across multiple types that lends itself to easier integration as a dataset. Benefits of this data type include the ability to use known good and known bad traffic that is easily identified and comes pre-formatted for simple pre-processing as already mentioned. Beyond the initial dataset for training, should this project prove successful, this source of data could be potentially analyzed by a trained model in real-time as a next generation method of indentification and countermeasures to malicious activity.

Using source code where available of known good and known bad software would in theory work the same way the Common Crawl dataset works currently. GPT has shown itself to "understand" programming and code as well as having the ability to provide recommendations regarding the improvement or fixing given code sequences when interacting with an analyst.

## Previous/Similar Work
Prior work in this realm has been performed by many organizations at this point. Some of the earliest examples include Cylance back in late 2012, which ultimately failed if I remember correctly. Current examples include CrowdStrike, Fortinet, Vectra, Nvidia, Sophos/Trellix, CheckPoint, and DarkTrace to name a few. This list of companies allegedly using machine learning in their products is quite large since the idea seems to have been renewed with the release of tools like ChatGPT, Bing's bot, and Google's Bard.

Most of these instances appear to be either using just the large language model to provide capabilities similar to ChatGPT or using in-house data via their specific industry tooling mixed with common machine learning to provide accelerated insights for customers into what is happening on their networks. MITRE has a project named [ATLAS](https://atlas.mitre.org) which appears to be a knowledge base of adversary tactics, techniques, and case studies for machine learning based on real-world observations, demonstrations from red teams and security groups, as well as the "state of the possible" from academic research. ATLAS is modeled after ATT&CK, but is intended to enable researchers to navigate threats specific to machine learning systems themselves according to their website. As such, it may be a candidate for inclusion into the training data.

With that being said, the ideas put forth here are just that, ideas. I am open to suggestions on how to improve this project, corrections of my assumptions, and constructive feedback. The idea is to actually improve cybersecurity, not present snake oil claims that won't actually work.

Based on this relatively short and limited amount of research, I think there is enough justification for a research project like I have just proposed that would ultimately more tightly tie these projects together and potentially provide incredible results for defensive cybersecurity work.
